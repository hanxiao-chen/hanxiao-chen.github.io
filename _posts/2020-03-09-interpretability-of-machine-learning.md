---
layout: post
title: Interpretability of machine learning
subtitle: A mind map
comments: true
---

![map](img/inter-map.png){: .center-block :}


### Reference
**[1] Mittelstadt, Brent and Russell, Chris and Wachter, Sandra, Explaining Explanations in AI (November 4, 2018). Proceedings of FAT* ’19: Conference on Fairness, Accountability, and Transparency (FAT* ’19), January 29–31, 2019, Atlanta, GA, USA. ACM, New York, NY, USA, doi/10.1145/3287560.3287574, ISBN: 978-1-4503-6125-5. Available at SSRN: https://ssrn.com/abstract=3278331
[2] Burrell, J. (2016). How the machine ‘thinks’: Understanding opacity in machine learning algorithms. Big Data & Society. https://doi.org/10.1177/2053951715622512
[3] Finale Doshi-Velez and Been Kim(2017), Towards A Rigorous Science of Interpretable Machine Learning. arXiv. https://arxiv.org/abs/1702.08608 **
